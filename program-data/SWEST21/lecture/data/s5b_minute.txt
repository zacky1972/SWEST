*************************************************************
セッションS5b 講演・チュートリアル(前半)
テーマ：組込みAI技術の最前線〜AISingのEdge向けAIアルゴリズムの紹介
講師：出澤 純一
日時：2019/9/6(金)
参加人数：約26名
*************************************************************

■最初に
倒立振り子の制御システム
機械自身が学習し賢くなっている

■AISing会社概要
社名：株式会社エイシング
英語表記：AISing Ltd.
代表者：出澤　純一

事業：製造業の生産性と品質の課題を解決する

OMRONとの事例：
OMRONの制御アルゴリズムにAISingのアルゴリズムを乗せた。
AISingはアルゴリズムと使い方だけを提供しOMRONが実際にその
アルゴリズムを使っていただくだけ。
AIのリテラシーがそんなに高くなくても導入することができる。


■VISION/MISSION
機械を賢くし、身近な生活を豊かにする
・AIをアルゴリズムから開発
・機械への知見
・組込みへの知見

■やっていること
認識　ディープラーニング
起動計画
制御←AISingの得意分野


■エッジAIのニーズ
既存AI：
クラウドサーバで学習を行い、エッジシステムで予測を行う。
通信コストと遅延という問題がある。

AiiR：
エッジシステムで学習可能。
軽量実装＋小変量対応
リアルタイム性＋逐次学習

そういった機械制御用AIアルゴリズムDeepBinaryTree（DBT）を提供

■DBTの特徴
Deep Binary Tree：
・ストリーミング学習（継足学習可）
常にモデルを更新し続けるため、モデルは劣化しない。
個々の差を考慮した個別制御モデルを作成できる。

・軽量、安価なデバイスでも稼働可
遅延することはない。計算時間は一定。
低パフォーマンスのコンピュータでも十分アルゴリズムを実行できる。

・説明可能AI
シングル木構造。
出力の経緯を説明できる。

■Deep Learningとの比較
DL：
・入力種別数：多い（数百万）
・メンテナンスコスト：高い
・学習速度：遅い
・説明可能：困難
・複雑タスクへの対応：可能
・学習制度：メンテナンス次第
・追加学習：静的な対応
・得意分野：画像認識・処理、音声認識、自然言語処理

DBT
・入力種別数：少ない（100個程度）
・メンテナンスコスト：低い
・学習速度：速い
・説明可能：可能
・複雑タスクへの対応：不向き
・学習制度：メンテフリーの高精度
・追加学習：動的な対応
・得意分野：機械制御、統計解析、予測制御


■AISingの目指す姿
エッジ側で分散学習を、クラウド上で統合学習を行うことで
集合モジュールを構築可能



■質問
DBPの階層が何層になるのか
場合によっては階層に浅いところと深い
どれだけ細かいレゾルーションにしたいかで深さがきまる
一番深いところの深さに合わせて浅いところも実行する



*************************************************************
セッションS5-b (後半)
テーマ：組込みAI技術の最前線〜FPGAによるAI実装 LUT-Networkの開発記
講師：山本 椋太
日時：2019/9/6(金) 
参加人数：約26名
*************************************************************

■アジェンダ
・FPGA×深層学習
・LUT-Networkとは
・実際にやってみた
・いろいろな比較


■深層学習
深層学習：様々な分野から注目されている。
組込みで動かすボトルネック
・メモリが足りない：MB・GBオーダーの訓練済みデータが必要になることもある。
・電力を抑えたい　：GPUは電力が大きい。
・速度が欲しい　　：リアルタイム性が要求されるシステムも存在。


FPGA×深層学習：
FPGA向けHDLの設計は専門性が高いため、
様々なフレームワークが研究・開発されている。
・GUINNESS
・BNN-PYNQ
今回はLUT-Networkを使う
■LUT-Networkとは
BinaryBrain：LUT（Look-up Table）-Network用の学習・推論を行う環境
特徴
・バイナリ入力・多値出力
・ニューラルネットワークのFPGA化
・バイナリネットだが変調技術により回帰分析が可能
・独自の確率的LUTのモデルにより、高速に学習
・C++で記述
・高速かつ微小リソースなFPGAアクセラレータを生成：MNISTコア単体


■DNNとLUT-Network
DNN：
ニューロンを使う

LUT-Network：
特定の入力パターンに対して割り当てられた（テーブル化されている）出力結果を渡すだけ。
テーブル化：入力のすべての組み合わせに対して、計算結果を表にしておく（1対1対応）

■バイナリ変調
DNN部分は入力から出力まですべてバイナリなので、DNNの入力前にオーバーサンプリングでバイナリ変調
・浮動小数点の入力をオーバーサンプリングしつつPWM変調など施したバイナリに変換するクラス
・BinaryToRealクラスというオーバーサンプリングされたバイナリを数えて浮動小数点に戻すクラス
これにより回帰問題が解けるようになる。

■確率的LUTモデル
StochasticLUT：
DNN部の入力はバイナリなのでStochastic演算が行え、この演算を持ち込んだもの。
変調したデータを用いることなく高速に学習可能。


■今後
シミュレーションはできており、実機もカメラを購入すれば動作させられる。


■質問
他のディープラーニングの方式とのアドバンテージ、ディスアドバンテージ
FPGA以外の者も含めて広くとらえた
Binary connect
Binarized Neural Network
XNOR-Network
と比較したLUT-Newtwork
メリット：
普通のフレームワークだと時間がかかっていたものがFPGAだと早い
デメリット：
PythonでやるGPUが多い
C++のカフェなどは慣れない人がいる


DSP九個どこに使っている？
性能のページ
復調や変調の部分だと思っている

ジンクでやられているが・・・
LCDはPSからでてる？PLから直接出てる？
カメラも薄い奴のなのでそこも
あんまりZynqで動かす必要がないのでは

畳み込みした後のOnline学習？
畳み込みだけだと精度は悪くならなくて、全結合で悪くなってしまうので、畳み込みでの劣化がおきる？
基礎ネットワークをどこまでそのまま変換できてるのかがわからない
入力と出力が1対1していない
雰囲気からすると落ちている気がしている
途中で劣化している

実用性の観点から見たときに精度がよくないという話はありましたが？
高い精度を求められるとこにはあまりよくない
難しい問題のときは評価をしないと議論
