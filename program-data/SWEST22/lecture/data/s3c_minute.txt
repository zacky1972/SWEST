**********************************************************************
セッション：S3c 
テーマ　　：Qumicoを使ったEdge AIの最新情報。AutoML、LSTM対応
　　　　　　～ ColabやLabelboxを使ったリモート時代の組込AI開発、人材育成
講師　　　：夏谷実   株式会社パソナテック (DX戦略本部)
日時　　　：2020/08/21(金) 11:30～12:40
参加人数　：12名
**********************************************************************


＜講師紹介＞
	株式会社パソナテック DX戦略本部 Qumico Product Manager
        夏谷 実
        FPGAやLSIの画像処理からDeepLearningの世界に入る
        Hatena id: natutan、Qiita id: natsutan
        TensorFlow Users Group KANSAIオーガナイザー

<はじめに>
       本講義ではハンズオンを実施
       Deep Learningの学習からC言語の変換までをブラウザで完結
       ラズパイが有ればDeep Learningが動かせる
       
<エッジAIの動向>
       一般的なAIサービスは何処かにあるサーバーでAIを処理する
       エッジAIはAIを処理するサーバーが無く、それぞれの端末がAIを実施
       エッジでデータを処理することで応答速度、通信量、消費電力の削減が可能
       エッジAIを使う理由
          ・エッジで処理するのでスケーリングで有利
          ・通信環境が悪くても動作する
          ・プライバシーを守りたい(画像を送信しない)

<業界動向>
       ONNX : AIの共通データフォーマット
           ONNXのランタイムエンジンを作れば様々なAIフレームワークに対応できる
  
           ONNXフォーマット
             中身はProtocol Buffer
              ・Model
              ・Graph
              ・Computation Graph

        Auto ML : Automated Machine Learning
           自動的に機械学習のパラメータを設定する技術
           Auto MLといった場合、GoogleのCloud AutoMLを指すことが多い
                Google以外のサービスが出てきているのでAutoMLが何をさすか確認する必要がある。
           Cloud Auto MLの実力
             画像の識別に関しては素人より優秀
             物体検出に関してはYOLO v2に近い数字(6万円くらいで評価できる)

           他のAuto ML フレームワーク
              ・Azure Custom Vision
              ・PFN Optuna
              ・Sony Prediction One
              ・Amazon Forecast

<Qumicoについて>
        目的: ディープラーニングの学習結果をエッジデバイス向けにc言語変換
              オープンソースとして公開
                https://github.com/PasonaTech-Inc/Qumico

        構成:
             DLフレームワークの学習モデル -> ONNX -> C言語 の返還を実施
 
        特徴:
             業界標準のフレームワークを使用可能
             SOCやカスタムCPUなどでも容易にエッジAIを動作可能

        画像だけではなく時系列データに対応(センサデータの異常検出など)

<これからのエッジAI開発>
        コロナ前: 
           滋賀県から東京に週2-3日ほど出張
        コロナ後:
           出張禁止でリモート開発

        リモート環境でやってみたこと
           LabelBox : オンラインのアノテーションサービス
                アノテーション画像をLabelboxにアップロード
                開発メンバがアップロードした画像をブラウザでアノテーション
                期間: 5月11日から6月10日
                メンバー: 4人
                データ数: 1849枚 (無料制限が厳しくて2500枚まで達成できず)

                良かったところ
                   ブラウザのみで完結 
                      Windows、Mac、Ubuntuすべてに対応するツールが他にない
                   画像を担当者に割り振る必要がない
                      割り振りはLaelboxでやってくれる

                上手くいかなかったところ
                   フィードバックに時間がかかる(slackだと時間がかかる)

            Google Colab : Jupyter notebookのクラウドベース
                良かったところ
                   上手くいかないときに履歴やエラーメッセージが全部残っている
                   colabファイルを共有するだけで状況の再現ができる
                   全員が同じ環境になる

                上手くいかなかったところ
                   長時間の学習中に接続が切れる
                   gitとの相性が悪い
                
           組み込み機器の画面をTeams/Zoomに出す
                ゲーム用のキャプチャ装置で画面を共有する

           Azure IoT
                 Docker imageの一斉デプロイ
                 メッセージ送受信 : ハンズオンで課題の結果を自動送信
                 AIモデルのリモート更新

<ワークショップの趣旨と現状>
         情報系以外の学生にもDeepLearningを体験できるようにしたい
             ハンズオンでワークショップを実施

         コロナの影響でワークショップを自習形式に変更
         データ収集から学習、ラズパイ動作までを実施
           扱うタスクは画像認識
 
         必要なアイテム
            Google アカウント: 無料登録にもクレジットカードが必要になるのが課題
            インターネットにつながるPC: OSの違いに対応するためColabで実施
            カメラとラズパイ

<Q&A>
   Q: 対応しているラズパイのバージョンは? 
　 A; バージョンは3B+

   Q: AWSと比較するとGoogleの方が成熟していますよね
   A: Googleの方が成熟している感触はあるが、変更が早くビジネスで使用するのが怖い
      AWSは仕様したことが無いのでMicrosoftと比較すると変更速度がおとなしい
